#!/usr/bin/env python

from yt.transfer_manager.flask_helpers import process_gzip
from yt.transfer_manager.logger import TaskIdLogger
from yt.transfer_manager.pattern_matching import match_copy_pattern

from yt.tools.logging_server import LogRecordSocketReceiver
from yt.tools.yamr import Yamr
from yt.tools.hadoop import Hive
from yt.tools.remote_copy_tools import \
    copy_yamr_to_yt_pull, \
    copy_yt_to_yamr_pull, \
    copy_yt_to_yamr_push, \
    copy_yt_to_kiwi, \
    copy_yt_to_yt, \
    copy_yt_to_yt_through_proxy, \
    copy_hive_to_yt, \
    Kiwi

from yt.wrapper.client import Yt
from yt.wrapper.common import generate_uuid, get_value
import yt.logger as logger
import yt.wrapper as yt

from flask import Flask, request, jsonify, Response, make_response

import os
import sys
import json
import time
import prctl
import signal
import socket
import logging
import logging.handlers
import thread
import argparse
import traceback
from copy import deepcopy
from datetime import datetime, timedelta
from collections import defaultdict
from subprocess32 import TimeoutExpired
from threading import RLock, Thread
from multiprocessing import Process, Queue

yt.config.RETRY_READ = True

class RequestFailed(yt.YtError):
    pass

class IncorrectTokenError(RequestFailed):
    pass

class SchedulingError(yt.YtError):
    pass

class SafeThread(Thread):
    def __init__(self, group=None, target=None, name=None, terminate=None, args=None, kwargs=None):
        self._parent_pid = os.getpid()

        if args is None:
            args = ()
        if kwargs is None:
            kwargs = {}

        def safe_run(*args, **kwargs):
            try:
                target(*args, **kwargs)
            except KeyboardInterrupt:
                thread.interrupt_main()
                time.sleep(0.5)
                os.kill(self._parent_pid, signal.SIGTERM)
            except:
                logger.exception("Unknown exception")
                os.kill(self._parent_pid, signal.SIGINT)
                time.sleep(0.5)
                os.kill(self._parent_pid, signal.SIGTERM)

        super(SafeThread, self).__init__(group=group, target=safe_run, name=name, args=args, kwargs=kwargs)

def filter_out_keys(dict, keys):
    result = deepcopy(dict)
    for key in keys:
        if key in result:
            del result[key]
    return result

def remove_unsigned(obj):
    def is_uint(num):
        return isinstance(num, long) and (num < -2 ** 63 or num >= 2 ** 63)

    if isinstance(obj, list):
        result = []
        for value in obj:
            new_value = remove_unsigned(value)
            if not is_uint(new_value):
                result.append(new_value)
        return result
    elif isinstance(obj, dict):
        result = {}
        for key, value in obj.iteritems():
            new_value = remove_unsigned(value)
            if not is_uint(new_value):
                result[key] = new_value
        return result
    else:
        return obj

def truncate_stderrs_attributes(error, limit):
    if "stderrs" in error.attributes:
        error.attributes["details"] = error.attributes["stderrs"][:limit]
        del error.attributes["stderrs"]
    if hasattr(error, "inner_errors"):
        for inner_error in error.inner_errors:
            truncate_stderrs_attributes(inner_error)

def now():
    return str(datetime.utcnow().isoformat() + "Z")

class Task(object):
    # NB: destination table is missing if we copy to kiwi
    def __init__(self, source_cluster, source_table, destination_cluster, creation_time, id, state, user,
                 destination_table=None, source_database=None, source_cluster_token=None, token=None, destination_cluster_token=None, mr_user=None, error=None,
                 start_time=None, finish_time=None, copy_method=None, progress=None, backend_tag=None, kiwi_user=None, kwworm_options=None, pool=None, meta=None,
                 destination_compression_codec=None, destination_erasure_codec=None, destination_force_sort=None):
        self.source_cluster = source_cluster
        self.source_table = source_table
        self.source_database = source_database
        self.source_cluster_token = get_value(source_cluster_token, token)
        self.destination_cluster = destination_cluster
        self.destination_table = destination_table
        self.destination_cluster_token = get_value(destination_cluster_token, token)

        self.creation_time = creation_time
        self.start_time = start_time
        self.finish_time = finish_time
        self.state = state
        self.id = id
        self.user = user
        self.mr_user = mr_user
        self.error = error
        self.token = get_value(token, "")
        self.copy_method = get_value(copy_method, "pull")
        self.progress = progress

        self.backend_tag = backend_tag
        self.pool = pool
        self.kiwi_user = kiwi_user
        self.kwworm_options = kwworm_options

        self.destination_compression_codec = destination_compression_codec
        self.destination_erasure_codec = destination_erasure_codec
        self.destination_force_sort = destination_force_sort

        # Special field to store meta-information for web-interface
        self.meta = meta

    def get_queue_id(self):
        return self.source_cluster, self.destination_cluster

    def get_source_client(self, clusters):
        if self.source_cluster not in clusters:
            raise yt.YtError("Unknown cluster " + self.source_cluster)
        client = deepcopy(clusters[self.source_cluster])
        if client._type == "yt":
            client.token = self.source_cluster_token
        if client._type == "yamr" and self.mr_user is not None:
            client.mr_user = self.mr_user
        return client

    def get_destination_client(self, clusters):
        if self.destination_cluster not in clusters:
            raise yt.YtError("Unknown cluster " + self.destination_cluster)
        client = deepcopy(clusters[self.destination_cluster])
        if client._type == "yt":
            client.token = self.destination_cluster_token
        if client._type == "yamr" and self.mr_user is not None:
            client.mr_user = self.mr_user
        return client

    def dict(self, hide_token=False, fields=None):
        result = deepcopy(self.__dict__)
        if hide_token:
            for key in ["token", "source_cluster_token", "destination_cluster_token"]:
                del result[key]
        for key in result.keys():
            if result[key] is None or (fields is not None and key not in fields) or key.startswith("_"):
                del result[key]
        return result

class Application(object):
    ERROR_BUFFER_SIZE = 2 ** 16

    def __init__(self, config):
        self._daemon = Flask(__name__)

        self._config = config
        self._mutex = RLock()
        self._yt = Yt(config["proxy"])
        self._yt.token = config["token"]

        self._load_config(config)
        self._path = config["path"]
        self._logging_port = self._config["port"] + 1

        # Run logging process. It inherits current logging configuration.
        self._logging_process = Process(target=self._run_logging_server, name="LoggingThread")
        self._logging_process.daemon = True
        self._logging_process.start()
        # Replace current logger with socket logger.
        logger.LOGGER.handlers = [logging.handlers.SocketHandler('localhost', self._logging_port)]

        self._sleep_step = 0.5

        # Prepare auth node if it is missing
        self._auth_path = os.path.join(config["path"], "auth")
        self._yt.create("map_node", self._auth_path, ignore_existing=True)

        # Run lock thread
        self._terminating = False
        self._lock_acquired = False
        self._lock_path = os.path.join(config["path"], "lock")
        self._lock_timeout = 10.0
        self._yt.create("map_node", self._lock_path, ignore_existing=True)
        self._lock_thread = SafeThread(target=self._take_lock, name="LockThread")
        self._lock_thread.daemon = True
        self._lock_thread.start()

        # Run execution thread
        self._task_processes = {}
        self._execution_thread = SafeThread(target=self._execute_tasks, name="SchedulingThread")
        self._execution_thread.daemon = True
        self._execution_thread.start()

        # Add rules
        self._add_rule("/", 'main', methods=["GET"], depends_on_lock=False)
        self._add_rule("/tasks/", 'get_tasks', methods=["GET"])
        self._add_rule("/tasks/", 'add', methods=["POST"])
        self._add_rule("/tasks/<id>/", 'get_task', methods=["GET"])
        self._add_rule("/tasks/<id>/", 'delete_task', methods=["DELETE"])
        self._add_rule("/tasks/<id>/abort/", 'abort', methods=["POST"])
        self._add_rule("/tasks/<id>/restart/", 'restart', methods=["POST"])
        self._add_rule("/config/", 'config', methods=["GET"])
        self._add_rule("/ping/", 'ping', methods=["GET"])
        self._add_rule("/match/", 'match', methods=["POST"])

    def terminate(self):
        self._terminating = True
        self._lock_thread.join(self._sleep_step)
        self._execution_thread.join(self._sleep_step)

    def _add_rule(self, rule, endpoint, methods, depends_on_lock=True):
        methods.append("OPTIONS")
        self._daemon.add_url_rule(
            rule,
            endpoint,
            self._process_lock(
                process_gzip(
                    self._process_cors(
                        self._process_exception(
                            Application.__dict__[endpoint]
                        ),
                        methods)
                    ),
                depends_on_lock),
            methods=methods)

    def _process_lock(self, func, depends_on_lock):
        def decorator(*args, **kwargs):
            if depends_on_lock and not self._lock_acquired:
                return "Cannot take lock", 500
            return func(*args, **kwargs)
        return decorator

    def _process_cors(self, func, methods):
        def decorator(*args, **kwargs):
            if request.method == "OPTIONS":
                rsp = self._daemon.make_default_options_response()
                rsp.headers["Access-Control-Allow-Origin"] = "*"
                rsp.headers["Access-Control-Allow-Methods"] = ", ".join(methods)
                rsp.headers["Access-Control-Allow-Headers"] = ", ".join(["Authorization", "Origin", "Content-Type", "Accept"])
                rsp.headers["Access-Control-Max-Age"] = 3600
                return rsp
            else:
                rsp = make_response(func(self, *args, **kwargs))
                rsp.headers["Access-Control-Allow-Origin"] = "*"
                return rsp

        return decorator

    def _process_exception(self, func):
        def decorator(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except RequestFailed as error:
                logger.exception(yt.errors.format_error(error))
                return json.dumps(error.simplify()), 400
            except Exception as error:
                logger.exception(error)
                return json.dumps({"code": 1, "message": "Unknown error: " + str(error)}), 502

        return decorator

    def _take_lock(self):
        yt_client = deepcopy(self._yt)
        with yt_client.PingableTransaction():
            while True:
                try:
                    yt_client.lock(self._lock_path)
                    break
                except yt.YtError as err:
                    if err.is_concurrent_transaction_lock_conflict():
                        logger.info("Failed to take lock")
                        time.sleep(self._lock_timeout)
                        continue
                    logger.exception(yt.errors.format_error(err))
                    return

            logger.info("Lock acquired")

            # Loading tasks from cypress
            self._load_tasks(os.path.join(self._path, "tasks"))

            self._lock_acquired = True

            # Set attribute outside of transaction
            self._yt.set_attribute(self._path, "address", socket.getfqdn())

            # Sleep infinitely long
            while True:
                if self._terminating:
                    return
                time.sleep(self._sleep_step)


    def _load_config(self, config):
        self._configure_logging(config.get("logging", {}))

        self._clusters = {}
        for name, cluster_description in config["clusters"].iteritems():
            type = cluster_description["type"]
            options = cluster_description["options"]

            if type == "yt":
                self._clusters[name] = Yt(**options)
                self._clusters[name]._pools = cluster_description.get("pools", {})
                self._clusters[name]._version = cluster_description.get("version", 0)
            elif type == "yamr":
                self._clusters[name] = Yamr(**options)
            elif type == "kiwi":
                self._clusters[name] = Kiwi(**options)
            elif type == "hive":
                self._clusters[name] = Hive(**options)
            else:
                raise yt.YtError("Incorrect cluster type " + options["type"])

            self._clusters[name]._name = name
            self._clusters[name]._type = type
            self._clusters[name]._parameters = filter_out_keys(cluster_description, ["type", "options"])

        self._availability_graph = deepcopy(config["availability_graph"])

        for name in self._availability_graph:
            edges = {}
            for neighbour in self._availability_graph[name]:
                if isinstance(neighbour, dict):
                    edges[neighbour["name"]] = neighbour.get("options", {})
                else:
                    edges[neighbour] = {}
            self._availability_graph[name] = edges

        for name in self._availability_graph:
            if name not in self._clusters:
                raise yt.YtError("Incorrect availability graph, cluster {} is missing".format(name))
            for neighbour in self._availability_graph[name]:
                if neighbour not in self._clusters:
                    raise yt.YtError("Incorrect availability graph, cluster {} is missing".format(neighbour))

        self.kiwi_transmitter = None
        if "kiwi_transmitter" in config:
            name = config["kiwi_transmitter"]
            if name not in self._clusters:
                raise yt.YtError("Incorrect kiwi transmitter, clustter {} is missing".format(name))
            self.kiwi_transmitter = self._clusters[name]
            if self.kiwi_transmitter._type != "yt":
                raise yt.YtError("Kiwi transmitter must be YT cluster")


    def _configure_logging(self, logging_node):
        level = logging.__dict__[logging_node.get("level", "INFO")]

        if "filename" in logging_node:
            handler = logging.handlers.WatchedFileHandler(logging_node["filename"])
        else:
            handler = logging.StreamHandler()

        new_logger = logging.getLogger("Transfer manager")
        new_logger.propagate = False
        new_logger.setLevel(level)
        new_logger.handlers = [handler]
        new_logger.handlers[0].setFormatter(logger.BASIC_FORMATTER)
        logger.LOGGER = new_logger

        logging.getLogger('werkzeug').setLevel(level)
        logging.getLogger('werkzeug').addHandler(handler)

    def _run_logging_server(self):
        prctl.set_pdeathsig(signal.SIGINT)
        socket_reciever = LogRecordSocketReceiver(lambda record: logger.LOGGER.handle(record),
                                                  port=self._logging_port)
        socket_reciever.serve_until_stopped()

    def _load_tasks(self, tasks_path):
        logger.info("Loading tasks from cypress")

        self._tasks_path = tasks_path
        if not self._yt.exists(self._tasks_path):
            self._yt.create("map_node", self._tasks_path)

        # From id to task description
        self._tasks = {}

        # From ... to task ids
        self._running_tasks_queues = defaultdict(lambda: [])
        self._runned_during_heartbeat = set()
        self._last_scheduled_time = defaultdict(lambda: datetime(year=1970, month=1, day=1))

        # List of tasks sorted by creation time
        self._pending_tasks = []

        # Number of pending tasks per user
        self._pending_tasks_per_user = defaultdict(lambda: 0)

        for id, options in self._yt.get(tasks_path).iteritems():
            task = Task(**options)

            active_client, passive_client = self._get_active_and_passive_clients(task)
            if active_client._type != "yt":
                continue

            if task.pool is None:
                logger.warning("Cannot load task %s: task has no pool", id)
                continue

            self._tasks[id] = task
            if task.state == "running":
                self._change_task_state(id, "pending")
            if task.state == "pending":
                self._append_pending_task(task)

        self._pending_tasks.sort(key=lambda id: self._tasks[id].creation_time)

        logger.info("Tasks load")

    def _append_pending_task(self, task):
        self._pending_tasks.append(task.id)
        self._pending_tasks_per_user[task.user] += 1

    def _change_task_state(self, id, new_state):
        with self._mutex:
            old_state = self._tasks[id].state
            self._tasks[id].state = new_state
            self._dump_task(id)
            logger.info("Task %s change state: %s -> %s", id, old_state, new_state)

    def _dump_task(self, id):
        with self._mutex:
            self._yt.set(os.path.join(self._tasks_path, id), remove_unsigned(self._tasks[id].dict()))

    def _create_pool(self, yt_client, destination_cluster_name):
        pool_name = "transfer_" + destination_cluster_name
        pool_path = "//sys/pools/transfer_manager/" + pool_name
        yt_client = deepcopy(yt_client)
        yt_client.token = self._yt.token
        if not yt_client.exists(pool_path):
            yt_client.create("map_node", pool_path, recursive=True, ignore_existing=True)
            yt_client.set(pool_path + "/@resource_limits", {"user_slots": 200})
            yt_client.set(pool_path + "/@mode", "fifo")
        while not yt_client.exists("//sys/scheduler/orchid/scheduler/pools/" + pool_name):
            time.sleep(0.5)
        return pool_name

    # Return pair: active client, that run copy operation and passive client.
    def _get_active_and_passive_clients(self, task):
        source_client = task.get_source_client(self._clusters)
        destination_client = task.get_destination_client(self._clusters)

        if destination_client._type == "yamr":
            if source_client._type == "yt" and task.copy_method == "push":
                return source_client, destination_client
            return destination_client, source_client
        elif destination_client._type == "yt":
            return destination_client, source_client
        else: # _type == "kiwi"
            return self.kiwi_transmitter, source_client

    def _initialize_pool(self, task):
        if task.pool is not None:
            return

        active_client, passive_client = self._get_active_and_passive_clients(task)
        if active_client._type != "yt":
            return

        name = passive_client._name
        if name in active_client._pools:
            pool = active_client._pools[name]
        else:
            pool = self._create_pool(active_client, name)
        task.pool = pool

    def _get_token(self, authorization_header):
        words = authorization_header.split()
        if len(words) != 2 or words[0].lower() != "oauth":
            return None
        return words[1]

    def _get_token_and_user(self, authorization_header):
        token = self._get_token(request.headers.get("Authorization", ""))
        if token is None or token == "undefined":
            user = "guest"
            token = ""
        else:
            user = self._yt.get_user_name(token)
            if not user:
                raise IncorrectTokenError("Authorization token is incorrect: " + token)
        return token, user

    def _check_permission(self, id, authorization_header, action_name):
        _, user = self._get_token_and_user(authorization_header)
        if self._tasks[id].user != user and \
           self._yt.check_permission(user, "administer", self._auth_path)["action"] != "allow":
            raise RequestFailed("{0} task is not permitted.".format(action_name))

    def _precheck(self, task, ignore_timeout=False, yamr_timeout=None, custom_logger=None):
        if custom_logger is None:
            custom_logger = logger

        # TODO(ignat): add timeout for yt
        custom_logger.info("Starting precheck")
        source_client = task.get_source_client(self._clusters)
        destination_client = task.get_destination_client(self._clusters)

        if task.copy_method not in ["pull", "push"]:
            raise yt.YtError("Incorrect copy method: " + str(task.copy_method))

        if task.source_cluster not in self._availability_graph or \
           task.destination_cluster not in self._availability_graph[task.source_cluster]:
            raise yt.YtError("Cluster {} not available from {}".format(task.destination_cluster, task.source_cluster))

        try:
            if yamr_timeout is not None:
                if source_client._type == "yamr":
                    source_client._light_command_timeout = yamr_timeout
                if destination_client._type == "yamr":
                    destination_client._light_command_timeout = yamr_timeout

            if source_client._type == "yamr" and source_client.is_empty(task.source_table) or \
               source_client._type == "yt" and (
                    not source_client.exists(task.source_table) or
                    source_client.get_attribute(task.source_table, "row_count") == 0):
                raise yt.YtError("Source table {} is empty".format(task.source_table))

            if source_client._type == "yt" and destination_client._type == "yamr":
                path = yt.TablePath(task.source_table, end_index=1, simplify=False)
                keys = list(source_client.read_table(path, format=yt.JsonFormat(), raw=False).next())
                if set(keys + ["subkey"]) != set(["key", "subkey", "value"]):
                    raise yt.YtError("Keys in the source table must be a subset of ('key', 'subkey', 'value')")

            if destination_client._type == "yt":
                destination_dir = os.path.dirname(task.destination_table)
                if not destination_client.exists(destination_dir):
                    raise yt.YtError("Destination directory {} should exist".format(destination_dir))
                destination_user = destination_client.get_user_name(task.destination_cluster_token)
                if destination_user is None or destination_client.check_permission(destination_user, "write", destination_dir)["action"] != "allow":
                    raise yt.YtError("There is no permission to write to {}. Please log in.".format(task.destination_table))

            if destination_client._type == "kiwi" and self.kiwi_transmitter is None:
                raise yt.YtError("Transimission cluster for transfer to kiwi is not configured")
            if source_client._type == "hive" and task.source_database is None:
                raise yt.YtError("Source database is not set")
        except TimeoutExpired:
            custom_logger.info("Precheck timed out")
            if not ignore_timeout:
                raise
            return

        custom_logger.info("Precheck completed")

    def _can_run(self, task):
        if task.get_queue_id() in self._runned_during_heartbeat:
            return False
        if len(self._running_tasks_queues[task.get_queue_id()]) >= self._config["running_tasks_limit_per_direction"]:
            return False
        if datetime.now() - self._last_scheduled_time[task.get_queue_id()] < timedelta(seconds=self._config["scheduling_backoff"]):
            return False

        client, _ = self._get_active_and_passive_clients(task)
        if client._type == "yt":
            if task.pool is None:
                raise SchedulingError("Task has no pool")
            pool_path = "//sys/scheduler/orchid/scheduler/pools/" + task.pool
            if not client.exists(pool_path):
                raise SchedulingError("Pool %s does not exist" % task.pool)

            pool_info = client.get("//sys/scheduler/orchid/scheduler/pools/" + task.pool)
            usage_ratio = 0.0
            for resource, usage in pool_info["resource_usage"].iteritems():
                limit = pool_info["resource_limits"][resource]
                if limit == 0:
                    usage_ratio = 1.0
                else:
                    usage_ratio = max(usage_ratio, float(usage) / limit)
            if usage_ratio > 0.95:
                result = False
            else:
                result = True

            return result

        return True

    def _execute_tasks(self):
        while True:
            if self._terminating:
                return

            if not self._lock_acquired:
                time.sleep(self._lock_timeout)
                continue

            logger.info("Processing tasks")

            with self._mutex:
                logger.info("Progress: %d running, %d pending tasks found", len(self._task_processes), len(self._pending_tasks))

                for id, (process, message_queue) in self._task_processes.items():
                    logger.info("Task %s running", id)
                    error = None
                    completed = False
                    while not message_queue.empty():
                        message = None
                        try:
                            message = message_queue.get_nowait()
                        except Queue.Empty:
                            break

                        if message["type"] == "error":
                            error = message["error"]
                        elif message["type"] == "operation_started":
                            self._tasks[id].progress["operations"].append(message["operation"])
                            self._dump_task(id)
                        elif message["type"] == "completed":
                            completed = True
                        else:
                            assert False, "Incorrect message type: " + message["type"]


                    if not process.is_alive() and not (process.aborted or error is not None or completed):
                        message = "Process died silently"
                        logger.warning(message)
                        error = {"message": message, "code": 1}

                    if process.aborted or error is not None or completed:
                        self._tasks[id].finish_time = now()
                        if completed:
                            if process.is_alive():
                                logger.warning("Task completed, but process still alive!")
                            self._change_task_state(id, "completed")
                        if error is not None:
                            self._tasks[id].error = error
                            self._change_task_state(id, "failed")

                        self._dump_task(id)
                        self._running_tasks_queues[self._tasks[id].get_queue_id()].remove(id)
                        del self._task_processes[id]

                for id in self._pending_tasks:
                    try:
                        if not self._can_run(self._tasks[id]):
                            logger.info("Task %s pending", id)
                            continue
                    except SchedulingError as error:
                        self._tasks[id].error = error.simplify()
                        self._change_task_state(id, "failed")
                        continue

                    queue_id = self._tasks[id].get_queue_id()
                    self._last_scheduled_time[queue_id] = datetime.now()
                    self._running_tasks_queues[queue_id].append(id)
                    self._runned_during_heartbeat.add(queue_id)
                    self._pending_tasks_per_user[self._tasks[id].user] -= 1

                    self._tasks[id].start_time = now()
                    self._tasks[id].progress = {"operations": []}
                    self._change_task_state(id, "running")

                    queue = Queue()
                    task_process = Process(target=lambda: self._execute_task(self._tasks[id], queue))
                    task_process.aborted = False
                    task_process.daemon = True
                    task_process.start()
                    self._task_processes[id] = (task_process, queue)

                self._pending_tasks = filter(lambda id: self._tasks[id].state == "pending", self._pending_tasks)
                self._runned_during_heartbeat.clear()

            time.sleep(self._sleep_step)

    def _execute_task(self, task, message_queue):
        prctl.set_pdeathsig(signal.SIGINT)
        logger.LOGGER = TaskIdLogger(task.id)

        logger.info("Start executing task")
        try:
            self._precheck(task)

            title = "Supervised by transfer task " + task.id
            task_spec = {
                "title": title,
                "transfer_manager": {
                    "task_id": task.id,
                    "backend_tag": task.backend_tag
                },
                "pool": task.pool
            }

            source_client = task.get_source_client(self._clusters)
            destination_client = task.get_destination_client(self._clusters)
            parameters = self._availability_graph[task.source_cluster][task.destination_cluster]

            # Calculate fastbone
            fastbone = source_client._parameters.get("fastbone", False) and destination_client._parameters.get("fastbone", False)
            fastbone = parameters.get("fastbone", fastbone)

            if source_client._type == "yt" and destination_client._type == "yt":
                logger.info("Running YT -> YT remote copy operation")
                if source_client._version != destination_client._version:
                    copy_yt_to_yt_through_proxy(
                        source_client,
                        destination_client,
                        task.source_table,
                        task.destination_table,
                        fastbone=fastbone,
                        spec_template=task_spec,
                        message_queue=message_queue)
                else:
                    network_name = "fastbone" if fastbone else "default"
                    network_name = parameters.get("network_name", network_name)
                    copy_yt_to_yt(
                        source_client,
                        destination_client,
                        task.source_table,
                        task.destination_table,
                        network_name=network_name,
                        spec_template=task_spec,
                        message_queue=message_queue)
            elif source_client._type == "yt" and destination_client._type == "yamr":
                logger.info("Running YT -> YAMR remote copy")
                if task.copy_method == "push":
                    copy_yt_to_yamr_push(
                        source_client,
                        destination_client,
                        task.source_table,
                        task.destination_table,
                        fastbone=fastbone,
                        spec_template=task_spec,
                        message_queue=message_queue)
                else:
                    copy_yt_to_yamr_pull(
                        source_client,
                        destination_client,
                        task.source_table,
                        task.destination_table,
                        fastbone=fastbone,
                        message_queue=message_queue)
            elif source_client._type == "yamr" and destination_client._type == "yt":
                logger.info("Running YAMR -> YT remote copy")
                copy_yamr_to_yt_pull(
                    source_client,
                    destination_client,
                    task.source_table,
                    task.destination_table,
                    fastbone=fastbone,
                    compression_codec=task.destination_compression_codec,
                    erasure_codec=task.destination_erasure_codec,
                    force_sort=task.destination_force_sort,
                    spec_template=task_spec,
                    message_queue=message_queue)
            elif source_client._type == "yamr" and destination_client._type == "yamr":
                destination_client.remote_copy(
                    source_client.server,
                    task.source_table,
                    task.destination_table,
                    fastbone=fastbone)
            elif source_client._type == "yt" and destination_client._type == "kiwi":
                dc_name = source_client._parameters.get("dc_name")
                if dc_name is not None:
                    task_spec["scheduling_tag"] = dc_name
                copy_yt_to_kiwi(
                    source_client,
                    destination_client,
                    self.kiwi_transmitter,
                    task.source_table,
                    fastbone=fastbone,
                    kiwi_user=task.kiwi_user,
                    kwworm_options=task.kwworm_options,
                    spec_template=task_spec,
                    message_queue=message_queue)
            elif source_client._type == "hive" and destination_client._type == "yt":
                copy_hive_to_yt(
                    source_client,
                    destination_client,
                    (task.source_database, task.source_table),
                    task.destination_table,
                    spec_template=task_spec,
                    message_queue=message_queue)
            else:
                raise Exception("Incorrect cluster types: {} source and {} destination".format(
                                source_client._type,
                                destination_client._type))
            logger.info("Task completed")

            message_queue.put({"type": "completed"})
        except KeyboardInterrupt:
            pass
        except yt.YtError as error:
            truncate_stderrs_attributes(error, self._config["error_details_length_limit"])
            logger.exception("Task {} failed with error {}".format(task.id, yt.errors.format_error(error)))
            message_queue.put({
                "type": "error",
                "error": error.simplify()
            })
        except Exception as error:
            logger.exception("Task failed with error:")
            message_queue.put({
                "type": "error",
                "error": {
                    "message": str(error),
                    "code": 1,
                    "attributes": {
                        "details": traceback.format_exc()
                    }
                }
            })

    def _get_task_description(self, task):
        task_description = task.dict(hide_token=True)
        queue_index = 1
        with self._mutex:
            for id in self._pending_tasks:
                if id == task.id:
                    task_description["queue_index"] = queue_index
                if self._tasks[id].get_queue_id() == task.get_queue_id():
                    queue_index += 1
        return task_description

    # Public interface
    def run(self, *args, **kwargs):
        self._daemon.run(*args, **kwargs)


    # Url handlers
    def main(self):
        return "This is YT transfer manager"

    def _create_task(self, params, token, user, dry_run, make_precheck):
        id = generate_uuid()
        logger.info("Adding task %s with id %s", json.dumps(params), id)

        # Move this check to precheck function
        required_parameters = set(["source_cluster", "source_table", "destination_cluster"])
        if not set(params) >= required_parameters:
            raise RequestFailed("All required parameters ({}) must be presented".format(", ".join(required_parameters)))
        if "destination_table" not in params:
            params["destination_table"] = None

        if "mr_user" not in params:
            params["mr_user"] = self._config.get("default_mr_user")
        if "kiwi_user" not in params:
            params["kiwi_user"] = self._config.get("default_kiwi_user")
        if "backend_tag" not in params:
            params["backend_tag"] = self._config.get("backend_tag")

        try:
            task = Task(id=id, creation_time=now(), user=user, token=token, state="pending", **params)
        except TypeError as error:
            raise RequestFailed("Cannot create task", inner_errors=[yt.YtError(error.message)])

        if len(self._pending_tasks) > self._config["pending_tasks_limit"]:
            raise RequestFailed("Too many pending tasks (>{0})".format(len(self._pending_tasks)))

        if self._pending_tasks_per_user[task.user] > self._config["pending_tasks_limit_per_user"]:
            raise RequestFailed("Too many pending tasks per user (>{0})".format(self._pending_tasks_per_user[task.user]))

        if make_precheck:
            try:
                self._precheck(task, ignore_timeout=True, yamr_timeout=5.0, custom_logger=TaskIdLogger(task.id))
            except yt.YtError as error:
                raise RequestFailed("Precheck of task {} failed".format(task.id), inner_errors=[error]), None, sys.exc_info()[2]

        if not dry_run:
            self._initialize_pool(task)
            self._yt.set(os.path.join(self._tasks_path, task.id), task.dict())
            with self._mutex:
                self._tasks[task.id] = task
                self._append_pending_task(task)
            logger.info("Task %s added", task.id)

        return task.id

    def add(self):
        try:
            params = json.loads(request.data)
        except ValueError as error:
            raise RequestFailed("Cannot parse JSON from body '{}'".format(request.data), inner_errors=[yt.YtError(error.message)])

        token, user = self._get_token_and_user(request.headers.get("Authorization", ""))
        dry_run = request.args.get("dry_run", False)

        if isinstance(params, list):
            ids = []
            for task_params in params:
                ids.append(self._create_task(params=task_params, token=token, user=user, dry_run=dry_run, make_precheck=False))
            return ids
        else:
            return self._create_task(params=params, token=token, user=user, dry_run=dry_run, make_precheck=True)

    def abort(self, id):
        if id not in self._tasks:
            raise RequestFailed("Unknown task " + id)

        logger.info("Aboring task %s", id)

        with self._mutex:
            self._check_permission(id, request.headers.get("Authorization", ""), "Aborting")

            if id in self._task_processes:
                process, _ = self._task_processes[id]
                process.aborted = True

                os.kill(process.pid, signal.SIGINT)
                time.sleep(0.5)
                if process.is_alive():
                    process.terminate()

            if id in self._pending_tasks:
                self._pending_tasks_per_user[self._tasks[id].user] -= 1
                self._pending_tasks.remove(id)

            if self._tasks[id].state not in ["aborted", "completed", "failed"]:
                self._change_task_state(id, "aborted")

        return ""

    def restart(self, id):
        if id not in self._tasks:
            raise RequestFailed("Unknown task " + id)

        logger.info("Restarting task %s", id)

        with self._mutex:
            self._check_permission(id, request.headers.get("Authorization", ""), "Restarting")
            if self._tasks[id].state not in ["completed", "aborted", "failed"]:
                raise RequestFailed("Cannot restart task in state " + self._tasks[id].state)

            self._tasks[id].state = "pending"
            self._tasks[id].creation_time = now()
            self._tasks[id].finish_time = None
            self._tasks[id].progress = None
            self._tasks[id].error = None
            self._dump_task(id)
            self._pending_tasks.append(id)

        return ""

    def get_task(self, id):
        if id not in self._tasks:
            return "Unknown task " + id, 400

        with self._mutex:
            tasks = deepcopy(self._tasks)
            pending_tasks = deepcopy(self._pending_tasks)

        task = tasks[id]
        task_description = task.dict(hide_token=True)
        queue_index = 1
        for id in pending_tasks:
            if id == task.id:
                task_description["queue_index"] = queue_index
                break
            if tasks[id].get_queue_id() == task.get_queue_id():
                queue_index += 1

        return jsonify(**task_description)

    def delete_task(self, id):
        if id not in self._tasks:
            return "Unknown task " + id, 400

        self._check_permission(id, request.headers.get("Authorization", ""), "Deleting")

        with self._mutex:
            if self._tasks[id].state not in ["completed", "aborted", "failed"]:
                raise RequestFailed("Cannot delete running task " + self._tasks[id].state)
            self._yt.remove(os.path.join(self._tasks_path, id), recursive=True)
            del self._tasks[id]

        return ""

    def get_tasks(self):
        with self._mutex:
            tasks = deepcopy(self._tasks)
            pending_tasks = deepcopy(self._pending_tasks)

        user = request.args.get("user")
        fields = request.args.getlist("fields[]")
        if not fields:
            fields = None
        if user is not None:
            tasks = [task.user == user for task in tasks]

        tasks_queue_indexes = {}
        queue_sizes = defaultdict(lambda: 0)
        for id in pending_tasks:
            queue_id = tasks[id].get_queue_id()
            queue_sizes[queue_id] += 1
            tasks_queue_indexes[id] = queue_sizes[queue_id]

        tasks_descriptions = []
        for id, task in tasks.iteritems():
            description = task.dict(hide_token=True, fields=fields)
            if id in tasks_queue_indexes:
                description["queue_index"] = tasks_queue_indexes[id]
            tasks_descriptions.append(description)

        return Response(json.dumps(tasks_descriptions), mimetype='application/json')

    def config(self):
        return jsonify(self._config)

    def ping(self):
        return "OK", 200

    def match(self):
        params = json.loads(request.data)
        source_pattern = params["source_pattern"]
        destination_pattern = params["destination_pattern"]
        source_cluster = params["source_cluster"]

        if source_cluster not in self._clusters:
            raise yt.YtError("Unknown cluster " + source_cluster)
        client = deepcopy(self._clusters[source_cluster])

        matchings = match_copy_pattern(client, source_pattern, destination_pattern)
        return Response(json.dumps(matchings), mimetype='application/json')


DEFAULT_CONFIG = {
    "clusters": {
        "quine": {
            "type": "yt",
            "options": {
                "proxy": "quine.yt.yandex.net",
            },
            "version": 2,
            "fastbone": True
        },
        "smith": {
            "type": "yt",
            "options": {
                "proxy": "smith.yt.yandex.net",
            },
            "version": 1,
            "fastbone": True
        },
        "plato": {
            "type": "yt",
            "options": {
                "proxy": "plato.yt.yandex.net",
            },
            "version": 1,
            "fastbone": True,
            "dc_name": "sas"
        },
        "cedar": {
            "type": "yamr",
            "options": {
                "server": "cedar00.search.yandex.net",
                "opts": "MR_NET_TABLE=ipv6",
                "binary": "/Berkanavt/bin/mapreduce-dev",
                "server_port": 8013,
                "http_port": 13013
            },
            "table_url_pattern": "https://specto.yandex.ru/cedar-viewer/table/?table=%table%",
            "fastbone": True
        },
        "redwood": {
            "type": "yamr",
            "options": {
                "server": "redwood00.search.yandex.net",
                "binary": "/Berkanavt/bin/mapreduce-dev",
                "server_port": 8013,
                "http_port": 13013,
                "timeout": 300
            },
            "table_url_pattern": "https://specto.yandex.ru/redwood-viewer/table/?table=%table%",
            "fastbone": True
        },
        "flux": {
            "type": "yt",
            "options": {
                "proxy": "flux.yt.yandex.net",
                "token": "93b4cacc08aa4538a79a76c21e99c0fb"
            }
        },
        "apterix": {
            "type": "kiwi",
            "options": {
                "url": "fb-kiwi1500.search.yandex.net",
                "kwworm": "/home/monster/kwworm"
            },
            "fastbone": True
        },
        "tasmania": {
            "type": "hive",
            "options": {
                "hcatalog_host": "v013h.hdp.yandex.net:50111",
                "hdfs_host": "v009h.hdp.yandex.net:14000",
                "hive_exporter_library": "/home/ignat/hive_import/hiveExporter.jar"
            }
        }
    },
    "kiwi_transmitter": "flux",
    "availability_graph": {
        "quine": ["cedar", "redwood", "plato", "smith"],
        "smith": ["cedar", "redwood", "quine", "plato"],
        "plato": ["cedar", "redwood", "quine", "smith", "apterix"],
        "cedar": ["redwood", "smith", "plato"],
        "redwood": ["cedar", "smith", "plato"],
        "tasmania": ["plato"]
    },
    "backend_tag": "testing",
    "default_mr_user": "userdata",
    "default_kiwi_user": "gemini",
    "scheduling_backoff": 5,
    "error_details_length_limit": 50000,
    "pending_tasks_limit": 5000,
    "pending_tasks_limit_per_user": 500,
    "running_tasks_limit_per_direction": 10,

    "path": "//home/ignat/transfer_manager_test",
    "proxy": "plato.yt.yandex.net",
    "token": "93b4cacc08aa4538a79a76c21e99c0fb",
    "port": 5010
}

def main():
    parser = argparse.ArgumentParser(description="Transfer manager.")
    parser.add_argument("--config")
    args = parser.parse_args()

    if args.config is not None:
        config = json.load(open(args.config))
    else:
        config = DEFAULT_CONFIG

    app = Application(config)
    app.run(host=config.get("host", "::"), port=config["port"], use_reloader=False, threaded=True)
    app.terminate()

if __name__ == "__main__":
    main()
