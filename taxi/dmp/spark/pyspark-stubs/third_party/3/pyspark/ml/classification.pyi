# Stubs for pyspark.ml.classification (Python 3.5)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from typing import Any, Optional
from pyspark.ml import Estimator, Model
from pyspark.ml.param.shared import *
from pyspark.ml.regression import DecisionTreeModel, RandomForestParams, TreeEnsembleModel, TreeEnsembleParams
from pyspark.ml.util import *
from pyspark.ml.wrapper import JavaEstimator, JavaModel
from pyspark.ml.wrapper import JavaWrapper

class JavaClassificationModel(JavaPredictionModel):
    @property
    def numClasses(self): ...

class LogisticRegression(JavaEstimator, HasFeaturesCol, HasLabelCol, HasPredictionCol, HasMaxIter, HasRegParam, HasTol, HasProbabilityCol, HasRawPredictionCol, HasElasticNetParam, HasFitIntercept, HasStandardization, HasThresholds, HasWeightCol, HasAggregationDepth, JavaMLWritable, JavaMLReadable):
    threshold = ...  # type: Any
    family = ...  # type: Any
    def __init__(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxIter: int = ..., regParam: float = ..., elasticNetParam: float = ..., tol: float = ..., fitIntercept: bool = ..., threshold: float = ..., thresholds: Optional[Any] = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., standardization: bool = ..., weightCol: Optional[Any] = ..., aggregationDepth: int = ..., family: str = ...) -> None: ...
    def setParams(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxIter: int = ..., regParam: float = ..., elasticNetParam: float = ..., tol: float = ..., fitIntercept: bool = ..., threshold: float = ..., thresholds: Optional[Any] = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., standardization: bool = ..., weightCol: Optional[Any] = ..., aggregationDepth: int = ..., family: str = ...): ...
    def setThreshold(self, value): ...
    def getThreshold(self): ...
    def setThresholds(self, value): ...
    def getThresholds(self): ...
    def setFamily(self, value): ...
    def getFamily(self): ...

class LogisticRegressionModel(JavaModel, JavaClassificationModel, JavaMLWritable, JavaMLReadable):
    @property
    def coefficients(self): ...
    @property
    def intercept(self): ...
    @property
    def coefficientMatrix(self): ...
    @property
    def interceptVector(self): ...
    @property
    def summary(self): ...
    @property
    def hasSummary(self): ...
    def evaluate(self, dataset): ...

class LogisticRegressionSummary(JavaWrapper):
    @property
    def predictions(self): ...
    @property
    def probabilityCol(self): ...
    @property
    def labelCol(self): ...
    @property
    def featuresCol(self): ...

class LogisticRegressionTrainingSummary(LogisticRegressionSummary):
    @property
    def objectiveHistory(self): ...
    @property
    def totalIterations(self): ...

class BinaryLogisticRegressionSummary(LogisticRegressionSummary):
    @property
    def roc(self): ...
    @property
    def areaUnderROC(self): ...
    @property
    def pr(self): ...
    @property
    def fMeasureByThreshold(self): ...
    @property
    def precisionByThreshold(self): ...
    @property
    def recallByThreshold(self): ...

class BinaryLogisticRegressionTrainingSummary(BinaryLogisticRegressionSummary, LogisticRegressionTrainingSummary): ...

class TreeClassifierParams:
    supportedImpurities = ...  # type: Any
    impurity = ...  # type: Any
    def __init__(self) -> None: ...
    def setImpurity(self, value): ...
    def getImpurity(self): ...

class GBTParams(TreeEnsembleParams):
    supportedLossTypes = ...  # type: Any

class DecisionTreeClassifier(JavaEstimator, HasFeaturesCol, HasLabelCol, HasPredictionCol, HasProbabilityCol, HasRawPredictionCol, DecisionTreeParams, TreeClassifierParams, HasCheckpointInterval, HasSeed, JavaMLWritable, JavaMLReadable):
    def __init__(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., maxDepth: int = ..., maxBins: int = ..., minInstancesPerNode: int = ..., minInfoGain: float = ..., maxMemoryInMB: int = ..., cacheNodeIds: bool = ..., checkpointInterval: int = ..., impurity: str = ..., seed: Optional[Any] = ...) -> None: ...
    def setParams(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., maxDepth: int = ..., maxBins: int = ..., minInstancesPerNode: int = ..., minInfoGain: float = ..., maxMemoryInMB: int = ..., cacheNodeIds: bool = ..., checkpointInterval: int = ..., impurity: str = ..., seed: Optional[Any] = ...): ...

class DecisionTreeClassificationModel(DecisionTreeModel, JavaClassificationModel, JavaMLWritable, JavaMLReadable):
    @property
    def featureImportances(self): ...

class RandomForestClassifier(JavaEstimator, HasFeaturesCol, HasLabelCol, HasPredictionCol, HasSeed, HasRawPredictionCol, HasProbabilityCol, RandomForestParams, TreeClassifierParams, HasCheckpointInterval, JavaMLWritable, JavaMLReadable):
    def __init__(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., maxDepth: int = ..., maxBins: int = ..., minInstancesPerNode: int = ..., minInfoGain: float = ..., maxMemoryInMB: int = ..., cacheNodeIds: bool = ..., checkpointInterval: int = ..., impurity: str = ..., numTrees: int = ..., featureSubsetStrategy: str = ..., seed: Optional[Any] = ..., subsamplingRate: float = ...) -> None: ...
    def setParams(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., maxDepth: int = ..., maxBins: int = ..., minInstancesPerNode: int = ..., minInfoGain: float = ..., maxMemoryInMB: int = ..., cacheNodeIds: bool = ..., checkpointInterval: int = ..., seed: Optional[Any] = ..., impurity: str = ..., numTrees: int = ..., featureSubsetStrategy: str = ..., subsamplingRate: float = ...): ...

class RandomForestClassificationModel(TreeEnsembleModel, JavaClassificationModel, JavaMLWritable, JavaMLReadable):
    @property
    def featureImportances(self): ...
    @property
    def trees(self): ...

class GBTClassifier(JavaEstimator, HasFeaturesCol, HasLabelCol, HasPredictionCol, HasMaxIter, GBTParams, HasCheckpointInterval, HasStepSize, HasSeed, JavaMLWritable, JavaMLReadable):
    lossType = ...  # type: Any
    def __init__(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxDepth: int = ..., maxBins: int = ..., minInstancesPerNode: int = ..., minInfoGain: float = ..., maxMemoryInMB: int = ..., cacheNodeIds: bool = ..., checkpointInterval: int = ..., lossType: str = ..., maxIter: int = ..., stepSize: float = ..., seed: Optional[Any] = ..., subsamplingRate: float = ...) -> None: ...
    def setParams(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxDepth: int = ..., maxBins: int = ..., minInstancesPerNode: int = ..., minInfoGain: float = ..., maxMemoryInMB: int = ..., cacheNodeIds: bool = ..., checkpointInterval: int = ..., lossType: str = ..., maxIter: int = ..., stepSize: float = ..., seed: Optional[Any] = ..., subsamplingRate: float = ...): ...
    def setLossType(self, value): ...
    def getLossType(self): ...

class GBTClassificationModel(TreeEnsembleModel, JavaPredictionModel, JavaMLWritable, JavaMLReadable):
    @property
    def featureImportances(self): ...
    @property
    def trees(self): ...

class NaiveBayes(JavaEstimator, HasFeaturesCol, HasLabelCol, HasPredictionCol, HasProbabilityCol, HasRawPredictionCol, HasThresholds, HasWeightCol, JavaMLWritable, JavaMLReadable):
    smoothing = ...  # type: Any
    modelType = ...  # type: Any
    def __init__(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., smoothing: float = ..., modelType: str = ..., thresholds: Optional[Any] = ..., weightCol: Optional[Any] = ...) -> None: ...
    def setParams(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., probabilityCol: str = ..., rawPredictionCol: str = ..., smoothing: float = ..., modelType: str = ..., thresholds: Optional[Any] = ..., weightCol: Optional[Any] = ...): ...
    def setSmoothing(self, value): ...
    def getSmoothing(self): ...
    def setModelType(self, value): ...
    def getModelType(self): ...

class NaiveBayesModel(JavaModel, JavaClassificationModel, JavaMLWritable, JavaMLReadable):
    @property
    def pi(self): ...
    @property
    def theta(self): ...

class MultilayerPerceptronClassifier(JavaEstimator, HasFeaturesCol, HasLabelCol, HasPredictionCol, HasMaxIter, HasTol, HasSeed, HasStepSize, JavaMLWritable, JavaMLReadable):
    layers = ...  # type: Any
    blockSize = ...  # type: Any
    solver = ...  # type: Any
    initialWeights = ...  # type: Any
    def __init__(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxIter: int = ..., tol: float = ..., seed: Optional[Any] = ..., layers: Optional[Any] = ..., blockSize: int = ..., stepSize: float = ..., solver: str = ..., initialWeights: Optional[Any] = ...) -> None: ...
    def setParams(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., maxIter: int = ..., tol: float = ..., seed: Optional[Any] = ..., layers: Optional[Any] = ..., blockSize: int = ..., stepSize: float = ..., solver: str = ..., initialWeights: Optional[Any] = ...): ...
    def setLayers(self, value): ...
    def getLayers(self): ...
    def setBlockSize(self, value): ...
    def getBlockSize(self): ...
    def setStepSize(self, value): ...
    def getStepSize(self): ...
    def setSolver(self, value): ...
    def getSolver(self): ...
    def setInitialWeights(self, value): ...
    def getInitialWeights(self): ...

class MultilayerPerceptronClassificationModel(JavaModel, JavaPredictionModel, JavaMLWritable, JavaMLReadable):
    @property
    def layers(self): ...
    @property
    def weights(self): ...

class OneVsRestParams(HasFeaturesCol, HasLabelCol, HasPredictionCol):
    classifier = ...  # type: Any
    def setClassifier(self, value): ...
    def getClassifier(self): ...

class OneVsRest(Estimator, OneVsRestParams, MLReadable, MLWritable):
    def __init__(self, featuresCol: str = ..., labelCol: str = ..., predictionCol: str = ..., classifier: Optional[Any] = ...) -> None: ...
    def setParams(self, featuresCol: Optional[Any] = ..., labelCol: Optional[Any] = ..., predictionCol: Optional[Any] = ..., classifier: Optional[Any] = ...): ...
    def copy(self, extra: Optional[Any] = ...): ...
    def write(self): ...
    def save(self, path): ...
    @classmethod
    def read(cls): ...

class OneVsRestModel(Model, OneVsRestParams, MLReadable, MLWritable):
    models = ...  # type: Any
    def __init__(self, models) -> None: ...
    def copy(self, extra: Optional[Any] = ...): ...
    def write(self): ...
    def save(self, path): ...
    @classmethod
    def read(cls): ...
