# Stubs for pyspark.sql.context (Python 3.5)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from typing import Any, Optional

class SQLContext:
    sparkSession = ...  # type: Any
    def __init__(self, sparkContext, sparkSession: Optional[Any] = ..., jsqlContext: Optional[Any] = ...) -> None: ...
    @classmethod
    def getOrCreate(cls, sc): ...
    def newSession(self): ...
    def setConf(self, key, value): ...
    def getConf(self, key, defaultValue: Optional[Any] = ...): ...
    @property
    def udf(self): ...
    def range(self, start, end: Optional[Any] = ..., step: int = ..., numPartitions: Optional[Any] = ...): ...
    def registerFunction(self, name, f, returnType: Any = ...): ...
    def registerJavaFunction(self, name, javaClassName, returnType: Optional[Any] = ...): ...
    def createDataFrame(self, data, schema: Optional[Any] = ..., samplingRatio: Optional[Any] = ..., verifySchema: bool = ...): ...
    def registerDataFrameAsTable(self, df, tableName): ...
    def dropTempTable(self, tableName): ...
    def createExternalTable(self, tableName, path: Optional[Any] = ..., source: Optional[Any] = ..., schema: Optional[Any] = ..., **options): ...
    def sql(self, sqlQuery): ...
    def table(self, tableName): ...
    def tables(self, dbName: Optional[Any] = ...): ...
    def tableNames(self, dbName: Optional[Any] = ...): ...
    def cacheTable(self, tableName): ...
    def uncacheTable(self, tableName): ...
    def clearCache(self): ...
    @property
    def read(self): ...
    @property
    def readStream(self): ...
    @property
    def streams(self): ...

class HiveContext(SQLContext):
    def __init__(self, sparkContext, jhiveContext: Optional[Any] = ...) -> None: ...
    def refreshTable(self, tableName): ...

class UDFRegistration:
    sqlContext = ...  # type: Any
    def __init__(self, sqlContext) -> None: ...
    def register(self, name, f, returnType: Any = ...): ...

