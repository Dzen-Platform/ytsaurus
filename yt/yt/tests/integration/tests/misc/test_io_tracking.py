from yt_env_setup import YTEnvSetup

from yt_commands import (
    authors, create, get, ls, read_journal, wait, read_table, write_journal,
    write_table, update_nodes_dynamic_config)

from yt_helpers import read_structured_log, write_log_barrier

import random

##################################################################


class TestDataNodeIOTracking(YTEnvSetup):
    NUM_MASTERS = 1
    NUM_NODES = 1
    NUM_SCHEDULERS = 1

    DELTA_MASTER_CONFIG = {
        "cypress_manager": {
            "default_table_replication_factor": 1,
            "default_journal_read_quorum": 1,
            "default_journal_write_quorum": 1,
            "default_journal_replication_factor": 1,
        }
    }

    def setup(self):
        update_nodes_dynamic_config({
            "data_node": {
                "io_tracker": {
                    "enable": True,
                    "enable_raw": True,
                    "period_quant": 10,
                    "aggregation_period": 5000,
                }
            }
        })
        self.node_address = ls("//sys/cluster_nodes")[0]

    def get_structured_log_path(self):
        return self.path_to_run + "/logs/node-0.json.log"

    def read_events(self, from_barrier=None, to_barrier=None):
        # NB. We need to filter out the IO generated by internal cluster processes. For example, scheduler
        # sometimes writes to //sys/scheduler/event_log. Such events are also logged in the data node and
        # may lead to unexpected test failures.
        raw_events = read_structured_log(
            self.get_structured_log_path(), from_barrier, to_barrier,
            category_filter={"IORaw"}, filter=lambda x: x["user@"] == "root")
        aggregate_events = read_structured_log(
            self.get_structured_log_path(), from_barrier, to_barrier,
            category_filter={"IOAggregate"}, filter=lambda x: x["user@"] == "root")
        return raw_events, aggregate_events

    def wait_for_events(self, raw_count=None, aggregate_count=None, from_barrier=None):
        def is_ready():
            to_barrier = write_log_barrier(self.node_address, "Barrier")
            raw_events, aggregate_events = self.read_events(from_barrier, to_barrier)
            return (raw_count is None or raw_count <= len(raw_events)) and \
                   (aggregate_count is None or aggregate_count <= len(aggregate_events))

        wait(is_ready)
        to_barrier = write_log_barrier(self.node_address, "Barrier")
        raw_events, aggregate_events = self.read_events(from_barrier, to_barrier)
        assert raw_count is None or raw_count == len(raw_events)
        assert aggregate_count is None or aggregate_count == len(aggregate_events)
        return raw_events, aggregate_events

    @authors("gepardo")
    def test_simple_write(self):
        from_barrier = write_log_barrier(self.node_address, "Barrier")
        create("table", "//tmp/table")
        write_table("//tmp/table", [{"a": 1, "b": 2, "c": 3}])
        raw_events, aggregate_events = self.wait_for_events(raw_count=1, aggregate_count=1, from_barrier=from_barrier)

        assert raw_events[0]["data_node_method@"] == "FinishChunk"
        for counter in ["byte_count", "io_count"]:
            assert raw_events[0][counter] > 0 and raw_events[0][counter] == aggregate_events[0][counter]

    @authors("gepardo")
    def test_two_chunks(self):
        from_barrier = write_log_barrier(self.node_address, "Barrier")
        create("table", "//tmp/table")
        write_table("//tmp/table", [{"number": 42, "good": True}])
        write_table("<append=%true>//tmp/table", [{"number": 43, "good": False}])
        raw_events, aggregate_events = self.wait_for_events(raw_count=2, aggregate_count=1, from_barrier=from_barrier)

        assert raw_events[0]["data_node_method@"] == "FinishChunk"
        assert raw_events[1]["data_node_method@"] == "FinishChunk"
        for counter in ["byte_count", "io_count"]:
            assert raw_events[0][counter] > 0
            assert raw_events[1][counter] > 0
            assert raw_events[0][counter] + raw_events[1][counter] == aggregate_events[0][counter]

    @authors("gepardo")
    def test_read_table(self):
        from_barrier = write_log_barrier(self.node_address, "Barrier")
        create("table", "//tmp/table")
        write_table("//tmp/table", [{"a": 1, "b": 2, "c": 3}])
        assert read_table("//tmp/table") == [{"a": 1, "b": 2, "c": 3}]
        raw_events, _ = self.wait_for_events(raw_count=2, from_barrier=from_barrier)

        assert raw_events[0]["data_node_method@"] == "FinishChunk"
        assert raw_events[1]["data_node_method@"] == "GetBlockSet"
        for counter in ["byte_count", "io_count"]:
            assert raw_events[0][counter] > 0
            assert raw_events[1][counter] > 0

    @authors("gepardo")
    def test_large_data(self):
        rnd = random.Random(42)

        create("table", "//tmp/table")

        for i in range(10):
            row_len = 50000
            row_count = 5
            # NB. The values are chosen in such a way so they cannot be compressed or deduplicated.
            large_data = [{
                "id": i,
                "sub_id": j,
                "data": bytes(bytearray([rnd.randint(0, 255) for _ in range(row_len)]))
            } for j in range(row_count)]

            old_disk_space = get("//tmp/table/@resource_usage/disk_space")
            from_barrier = write_log_barrier(self.node_address, "Barrier")
            write_table("<append=%true>//tmp/table", large_data)
            _, aggregate_events = self.wait_for_events(aggregate_count=1, from_barrier=from_barrier)
            new_disk_space = get("//tmp/table/@resource_usage/disk_space")

            min_data_bound = 0.95 * row_count * row_len
            max_data_bound = 1.05 * (new_disk_space - old_disk_space)

            assert aggregate_events[0]["data_node_method@"] == "FinishChunk"
            assert min_data_bound <= aggregate_events[0]["byte_count"] <= max_data_bound
            assert aggregate_events[0]["io_count"] > 0

            from_barrier = write_log_barrier(self.node_address, "Barrier")
            assert read_table("//tmp/table[#{}:]".format(i * row_count)) == large_data
            _, aggregate_events = self.wait_for_events(aggregate_count=1, from_barrier=from_barrier)

            assert aggregate_events[0]["data_node_method@"] == "GetBlockSet"
            assert min_data_bound <= aggregate_events[0]["byte_count"] <= max_data_bound
            assert aggregate_events[0]["io_count"] > 0

    @authors("gepardo")
    def test_journal(self):
        data = [{"data":  str(i)} for i in range(20)]

        from_barrier = write_log_barrier(self.node_address, "Barrier")
        create("journal", "//tmp/journal")
        write_journal("//tmp/journal", data)
        raw_events, _ = self.wait_for_events(raw_count=1, from_barrier=from_barrier)

        assert raw_events[0]["data_node_method@"] == "FlushBlocks"
        assert raw_events[0]["byte_count"] > 0
        assert raw_events[0]["io_count"] > 0

        from_barrier = write_log_barrier(self.node_address, "Barrier")
        assert read_journal("//tmp/journal") == data
        raw_events, _ = self.wait_for_events(raw_count=1, from_barrier=from_barrier)

        assert raw_events[0]["data_node_method@"] == "GetBlockRange"
        assert raw_events[0]["byte_count"] > 0
        assert raw_events[0]["io_count"] > 0

    @authors("gepardo")
    def test_large_journal(self):
        rnd = random.Random(42)
        row_len = 200000
        row_count = 5
        min_data_bound = 0.9 * row_count * row_len
        max_data_bound = 1.1 * row_count * row_len

        create("journal", "//tmp/journal")

        for i in range(10):
            # NB. The values are chosen in such a way so they cannot be compressed or deduplicated.
            data = [{"data": bytes(bytearray([rnd.randint(0, 255) for _ in range(row_len)]))} for _ in range(row_count)]

            from_barrier = write_log_barrier(self.node_address, "Barrier")
            write_journal("//tmp/journal", data)
            raw_events, _ = self.wait_for_events(raw_count=1, from_barrier=from_barrier)

            assert raw_events[0]["data_node_method@"] == "FlushBlocks"
            assert min_data_bound <= raw_events[0]["byte_count"] <= max_data_bound
            assert raw_events[0]["io_count"] > 0

            from_barrier = write_log_barrier(self.node_address, "Barrier")
            assert read_journal("//tmp/journal[#{}:#{}]".format(i * row_count, (i + 1) * row_count)) == data
            raw_events, _ = self.wait_for_events(raw_count=1, from_barrier=from_barrier)

            assert raw_events[0]["data_node_method@"] == "GetBlockRange"
            assert min_data_bound <= raw_events[0]["byte_count"] <= max_data_bound
            assert raw_events[0]["io_count"] > 0
