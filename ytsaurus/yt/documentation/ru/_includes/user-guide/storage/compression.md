# Сжатие 

В данном разделе описаны алгоритмы сжатия, поддерживаемые {{product-name}}.

В {{product-name}} пользовательские данные по умолчанию хранятся и передаются в сжатом виде. 

Система самостоятельно производит сжатие:
1. При записи в таблицу или файл данные разбиваются на части — [чанки](../../../user-guide/storage/chunks.md) — фиксированного размера. По умолчанию размер чанка составляет 16МБ. 
2. Каждый чанк сжимается алгоритмом, указанным для данного файла или таблицы, и записывается на диск.
3. Для передачи по сети данные считываются с диска уже в сжатом виде. 

## Просмотр алгоритма сжатия { #get_compression }

В системе {{product-name}} могут быть сжаты чанки, файлы и таблицы.

Алгоритм сжатия указан в атрибуте `compression_codec`: 

- Для чанков атрибут `compression_codec` задает алгоритм сжатия всех блоков чанка. Разные чанки внутри файла или таблицы могут быть сжаты с помощью разных алгоритмов.
- Для таблиц и файлов `compression_codec` определяет алгоритм сжатия по умолчанию. Он будет использован, если для отдельных чанков файла или таблицы алгоритм не указан. Значение `compression_codec` по умолчанию: для таблиц — `lz4`, для файлов — `none`.

Степень сжатия данных указана в атрибутах `compressed_data_size` и `uncompressed_data_size` чанка, таблицы или файла:

- Для чанков атрибут `uncompressed_data_size` показывает размер чанка до сжатия, атрибут `compressed_data_size` — размер чанка после сжатия.
- Для таблиц и файлов атрибут `uncompressed_data_size` показывает суммарный размер несжатых данных всех чанков объекта, атрибут `compressed_data_size` — размер сжатых данных.

Статистика по алгоритмам сжатия, используемых в чанках таблицы, содержится в атрибуте `compression_statistics` таблицы.

## Изменение алгоритма сжатия { #set_compression }

Чтобы изменить алгоритм сжатия существующей статической таблицы, установите новое значение атрибута `compression_codec`. Затем запустите команду `merge`, чтобы выполнить повторное сжатие чанков. 

CLI

```bash
yt set //path/to/table/@compression_codec zstd_3
yt merge --src //path/to/table --dst //path/to/table --spec '{force_transform = %true}'
```

Чтобы изменить алгоритм сжатия [динамической таблицы](../../../user-guide/dynamic-tables/overview.md), установите новое значение атрибута `compression_codec`. Затем выполните `remount-table`. 
Старые чанки со временем будут повторно сжаты в процессе компактификации. Скорость сжатия зависит от объема таблицы, скорости записи, настроек фоновой компактификации.

CLI

```bash
yt set //path/to/table/@compression_codec zstd_3
yt remount-table //path/to/table
```

Если в таблицу идёт постоянная запись, как правило, нет необходимости в [форсированном сжатии](../../../user-guide/dynamic-tables/compaction.md#forced_compaction). Если требуется форсировать сжатие, используйте `forced compaction`.

## Поддерживаемые алгоритмы сжатия { #compression_codecs }

| Алгоритм сжатия        | Описание         | Скорость сжатия/распаковки  | Степень сжатия  |
| ---------------------- | ---------------- | --------------------------- | --------------- |
| `none`                 | Без сжатия.                                 | -                                | -                                |
| `snappy`               | Подробнее об алгоритме [snappy](https://google.github.io/snappy/). | +++ | +- |
| `zlib_[1..9]`          | Система {{product-name}} поддерживает все 9 уровней. Чем больше уровень, тем сильнее и тем медленнее сжимаются данные. Подробнее об алгоритме [zlib](https://zlib.net). | ++ | ++ |
| `lz4`                  | Алгоритм сжатия по умолчанию для таблиц. Подробнее об алгоритме [lz4](https://lz4.github.io/lz4/). | +++ | + |
| `lz4_high_compression` | Алгоритм `lz4` c включенной опцией `high_compression`. Сжимает эффективнее, но существенно медленнее. По степени сжатия уступает `zlib`. | ++ | ++- |
| `zstd_[1..21]`         | Подробнее об алгоритме [zstd](https://github.com/facebook/zstd). | ++ | ++ |
| `brotli_[1..11]`       | Данный алгоритм рекомендуется к использованию для данных, которые не являются временными. Рекомендуется использовать уровни 3, 5 и 8 — они имеют лучшее соотношение объема и скорости. Подробнее об алгоритме [brotli](https://github.com/google/brotli). | ++ | +++ |
| `lzma_[0..9]`          | Подробнее об алгоритме [lzma](https://www.7-zip.org). | + | +++ |
| `bzip2_[1..9]`          | Подробнее об алгоритме [bzip2](http://www.bzip.org). | ++ | ++ |

## Рекомендации { #best_practice }

- Для файлов, которые используются в операции в виде [симлинков](../../../user-guide/storage/links.md) на чанки, чаще всего используется алгоритм `none`.
- `lz4` часто используется для актуальных данных. Алгоритм обеспечивает высокую скорость сжатия и распаковки при приемлемом коэффициенте сжатия.
- Когда необходимо максимальное сжатие, а длительное время работы является приемлемым, часто используется `brotli_8`.
- Для операций, состоящих из малого количества джобов, например, `final sort` или `sorted merge`, рекомендуется добавить отдельную стадию обработки — сжатие данных в операции merge с большим числом джобов. 

{% note warning "Внимание" %}

Хотя алгоритмы с сильным сжатием — `zlib`, `zstd`, `brotli` —  позволяют экономить место на диске, их скорость сжатия на порядок ниже, чем у алгоритма по умолчанию `lz4`. 
Использование алгоритмов с сильным сжатием может привести к значительному росту времени выполнения операций. Рекомендуется использовать их только для таблиц, которые занимают много места, но редко меняются.

{% endnote %}

{% if audience == internal %}

## Нерекомендуемые алгоритмы сжатия { #deprecated }

В версии 0.18.2 и выше часть алгоритмов сжатия не рекомендуются к использованию (deprecated):

- `brotli3`, `brotli5`, `brotli8` (>= 18.0) — алгоритмы, соответствующие 3, 5 и 8 уровням сжатия алгоритма [brotli](https://github.com/google/brotli). Сжимают эффективно, но медленно (150 mb/s, 50 mb/s, 20 mb/s соответственно). Используйте `brotli_3`, `brotli_5` и `brotli_8`.
- `zlib6` (`gzip_normal` до версии 0.17.3) —  рекомендуется использовать `zlib_6`.
- `zlib9` (`gzip_best_compression` до версии 0.17.3) — рекомендуется использовать `zlib_9`.
- `zstd` — рекомендуется использовать `zstd_[1..21]` с необходимым уровнем сжатия.

{% endif %}

## Сравнение алгоритмов сжатия { #benchmarks }

Данный способ работает только для статических таблиц. Чтобы определить, какой алгоритм лучше подойдет для определенной таблицы, запустите ```yt run-compression-benchmarks TABLE```. 
Из таблицы будет взят сэмпл, по умолчанию равный 1 ГБ. Он будет сжат всеми алгоритмами.
После завершения операции вы увидите ```codec/cpu/encode```, ```codec/cpu/decode``` и ```compression_ratio``` для каждого алгоритма.

Для алгоритмов с несколькими уровнями сжатия по умолчанию используются минимальный, средний и максимальный уровни. 
Чтобы получить результаты по всем уровням, используйте опцию ```--all-codecs```.

CLI
```bash
yt run-compression-benchmarks //home/dev/tutorial/compression_benchmark_data
```
```bash
[
    {
        "codec": "brotli_1",
        "codec/cpu/decode": 2103,
        "codec/cpu/encode": 2123,
        "compression_ratio": 0.10099302059669339
    },
    ...
    {
        "codec": "brotli_11",
        "codec/cpu/decode": "Not launched",
        "codec/cpu/encode": "Timed out", # сжатие не успело завершиться за стандартный --time-limit-sec (200)
        "compression_ratio": "Timed out"
    },
    ...
    {
        "codec": "none",
        "codec/cpu/decode": 0,
        "codec/cpu/encode": 247,
        "compression_ratio": 1.0
    },
    ...
    {
        "codec": "zstd_11",
        "codec/cpu/decode": 713,
        "codec/cpu/encode": 15283,
        "compression_ratio": 0.07451278201257201
    },
    ...
]
```
